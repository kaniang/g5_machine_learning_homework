{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalExamCode1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ansh941/MnistSimpleCNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4ECVXtd1pZW",
        "outputId": "5e6e59e3-4097-4c98-90ae-ba1a8b621e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MnistSimpleCNN'...\n",
            "remote: Enumerating objects: 507, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 507 (delta 4), reused 4 (delta 0), pack-reused 487\u001b[K\n",
            "Receiving objects: 100% (507/507), 622.69 MiB | 31.44 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## datasets.py"
      ],
      "metadata": {
        "id": "qgl7vGME-ARh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lokasi setiap datasets yang digunakan\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class MnistDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, training=True, transform=None):\n",
        "        if training==True:\n",
        "            f = open('MnistSimpleCNN/data/MNIST/raw/train-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('MnistSimpleCNN/data/MNIST/raw/train-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        else:\n",
        "            f = open('MnistSimpleCNN/data/MNIST/raw/t10k-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('MnistSimpleCNN/data/MNIST/raw/t10k-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        xs = np.reshape(xs, (-1, 28, 28, 1)).astype(np.float32)\n",
        "        ys = ys.astype(np.int)\n",
        "        self.x_data = xs\n",
        "        self.y_data = ys\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = Image.fromarray(self.x_data[idx].reshape(28, 28))\n",
        "        y = torch.tensor(np.array(self.y_data[idx]))\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        x = transforms.ToTensor()(np.array(x)/255)\n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "Mxn3jP2S_8ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ema.py"
      ],
      "metadata": {
        "id": "wQ8QYrwF99xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameter\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.original = {}\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def __call__(self, model, num_updates):\n",
        "        decay = min(self.decay, (1.0 + num_updates) / (10.0 + num_updates))\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                new_average = (1.0 - decay) * param.data + decay * self.shadow[name]\n",
        "                self.shadow[name] = new_average.clone()\n",
        "\n",
        "    def assign(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                self.original[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def resume(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                param.data = self.original[name]"
      ],
      "metadata": {
        "id": "CRWyl8NM92fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##transform.py"
      ],
      "metadata": {
        "id": "uIPPoPDQ-E7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data augmentasi\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as V\n",
        "\n",
        "class RandomRotation(object):\n",
        "    def __init__(self, degrees, seed=1):\n",
        "        self.degrees = (-degrees, degrees)\n",
        "        random.seed(seed)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_params(degrees):\n",
        "        angle = random.uniform(degrees[0], degrees[1])\n",
        "        return angle\n",
        "\n",
        "    def __call__(self, img):\n",
        "        angle = self.get_params(self.degrees)\n",
        "        return V.rotate(img, angle, False, False, None, None)"
      ],
      "metadata": {
        "id": "kpP8IOiq92jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## modelM3.py"
      ],
      "metadata": {
        "id": "f2E-Chej-S0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# membuat model dengan ukuran kernel 3x3\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, bias=False)       # output becomes 26x26\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 48, 3, bias=False)      # output becomes 24x24\n",
        "        self.conv2_bn = nn.BatchNorm2d(48)\n",
        "        self.conv3 = nn.Conv2d(48, 64, 3, bias=False)      # output becomes 22x22\n",
        "        self.conv3_bn = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 80, 3, bias=False)      # output becomes 20x20\n",
        "        self.conv4_bn = nn.BatchNorm2d(80)\n",
        "        self.conv5 = nn.Conv2d(80, 96, 3, bias=False)      # output becomes 18x18\n",
        "        self.conv5_bn = nn.BatchNorm2d(96)\n",
        "        self.conv6 = nn.Conv2d(96, 112, 3, bias=False)     # output becomes 16x16\n",
        "        self.conv6_bn = nn.BatchNorm2d(112)\n",
        "        self.conv7 = nn.Conv2d(112, 128, 3, bias=False)    # output becomes 14x14\n",
        "        self.conv7_bn = nn.BatchNorm2d(128)\n",
        "        self.conv8 = nn.Conv2d(128, 144, 3, bias=False)    # output becomes 12x12\n",
        "        self.conv8_bn = nn.BatchNorm2d(144)\n",
        "        self.conv9 = nn.Conv2d(144, 160, 3, bias=False)    # output becomes 10x10\n",
        "        self.conv9_bn = nn.BatchNorm2d(160)\n",
        "        self.conv10 = nn.Conv2d(160, 176, 3, bias=False)   # output becomes 8x8\n",
        "        self.conv10_bn = nn.BatchNorm2d(176)\n",
        "        self.fc1 = nn.Linear(11264, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n",
        "        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n",
        "        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n",
        "        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n",
        "        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n",
        "        flat1 = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "dfwEy84S92wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## modelM5.py"
      ],
      "metadata": {
        "id": "0NgKdy3a-ZSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# membuat model dengan ukuran kernel 5x5\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, bias=False)\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False)\n",
        "        self.conv2_bn = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 96, 5, bias=False)\n",
        "        self.conv3_bn = nn.BatchNorm2d(96)\n",
        "        self.conv4 = nn.Conv2d(96, 128, 5, bias=False)\n",
        "        self.conv4_bn = nn.BatchNorm2d(128)\n",
        "        self.conv5 = nn.Conv2d(128, 160, 5, bias=False)\n",
        "        self.conv5_bn = nn.BatchNorm2d(160)\n",
        "        self.fc1 = nn.Linear(10240, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        flat5 = torch.flatten(conv5.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat5))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "eu0IUztp92yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## modelM7.py"
      ],
      "metadata": {
        "id": "PfgsV2---ebO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# membuat model dengan ukuran kernel 7x7\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM7, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 48, 7, bias=False)    # output becomes 22x22\n",
        "        self.conv1_bn = nn.BatchNorm2d(48)\n",
        "        self.conv2 = nn.Conv2d(48, 96, 7, bias=False)   # output becomes 16x16\n",
        "        self.conv2_bn = nn.BatchNorm2d(96)\n",
        "        self.conv3 = nn.Conv2d(96, 144, 7, bias=False)  # output becomes 10x10\n",
        "        self.conv3_bn = nn.BatchNorm2d(144)\n",
        "        self.conv4 = nn.Conv2d(144, 192, 7, bias=False) # output becomes 4x4\n",
        "        self.conv4_bn = nn.BatchNorm2d(192)\n",
        "        self.fc1 = nn.Linear(3072, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        flat1 = torch.flatten(conv4.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "5zv6eWV_920s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "3FH8ZP8G-pIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports module\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "\n",
        "def run(p_seed=0, p_epochs=3, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "    # random number generator seed ------------------------------------------------#\n",
        "    SEED = p_seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    # ukuran kernel dari model\n",
        "    KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "    # jumlah epoch yang akan dilakukan\n",
        "    NUM_EPOCHS = p_epochs\n",
        "\n",
        "    # nama dan lokasi file yang dipakai\n",
        "    if not os.path.exists(\"MnistSimpleCNN/logs/%s\"%p_logdir):\n",
        "        os.makedirs(\"MnistSimpleCNN/logs/%s\"%p_logdir)\n",
        "    OUTPUT_FILE = str(\"MnistSimpleCNN/logs/%s/log%03d.out\"%(p_logdir,SEED))\n",
        "    MODEL_FILE = str(\"MnistSimpleCNN/logs/%s/model%03d.pth\"%(p_logdir,SEED))\n",
        "\n",
        "    # enable GPU usage ------------------------------------------------------------#\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # augmentasi data\n",
        "    transform = transforms.Compose([\n",
        "        RandomRotation(20, seed=SEED),\n",
        "        transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
        "        ])\n",
        "\n",
        "    # memuat data yang akan ditrain\n",
        "    train_dataset = MnistDataset(training=True, transform=transform)\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=120, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # pemilihan model, ada 3 model yang tersedia(3,5,7)\n",
        "    if(KERNEL_SIZE == 3):\n",
        "        model = ModelM3().to(device)\n",
        "    elif(KERNEL_SIZE == 5):\n",
        "        model = ModelM5().to(device)\n",
        "    elif(KERNEL_SIZE == 7):\n",
        "        model = ModelM7().to(device)\n",
        "\n",
        "    summary(model, (1, 28, 28))\n",
        "\n",
        "    # hyperparameter selection ----------------------------------------------------#\n",
        "    ema = EMA(model, decay=0.999)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
        "\n",
        "    # delete result file ----------------------------------------------------------#\n",
        "    f = open(OUTPUT_FILE, 'w')\n",
        "    f.close()\n",
        "\n",
        "    # global variables ------------------------------------------------------------#\n",
        "    g_step = 0\n",
        "    max_correct = 0\n",
        "\n",
        "    # perulangan pada proses training\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # train process                                                            #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_corr = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            train_pred = output.argmax(dim=1, keepdim=True)\n",
        "            train_corr += train_pred.eq(target.view_as(train_pred)).sum().item()\n",
        "            train_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            g_step += 1\n",
        "            ema(model, g_step)\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = 100 * train_corr / len(train_loader.dataset)\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # test process                                                             #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        model.eval()\n",
        "        ema.assign(model)\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total_pred = np.zeros(0)\n",
        "        total_target = np.zeros(0)\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                total_pred = np.append(total_pred, pred.cpu().numpy())\n",
        "                total_target = np.append(total_target, target.cpu().numpy())\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            if(max_correct < correct):\n",
        "                torch.save(model.state_dict(), MODEL_FILE)\n",
        "                max_correct = correct\n",
        "                print(\"Best accuracy! correct images: %5d\"%correct)\n",
        "        ema.resume(model)\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # output                                                                   #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "        best_test_accuracy = 100 * max_correct / len(test_loader.dataset)\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) (best: {:.2f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), test_accuracy, best_test_accuracy))\n",
        "\n",
        "        f = open(OUTPUT_FILE, 'a')\n",
        "        f.write(\" %3d %12.6f %9.3f %12.6f %9.3f %9.3f\\n\"%(epoch, train_loss, train_accuracy, test_loss, test_accuracy, best_test_accuracy))\n",
        "        f.close()\n",
        "\n",
        "        \n",
        "        # pembaruan pada learning rate yang akan diperbarui setiap epoch dengan menganbil nilai tertinggi\n",
        "     \n",
        "        lr_scheduler.step()\n",
        "\n",
        "p_seed = int(input (\"Seeds: \")) # input seeds value\n",
        "p_epoch = int(input (\"Epoch: \")) #input epoch value in each trial\n",
        "p_trials = int(input (\"Trials: \")) #input trial value\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #input size kernel\n",
        "p_gpu = int(input (\"GPU: \")) #input GPU value\n",
        "p_logdir = input (\"Logdir: \") #input model\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(p_gpu)\n",
        "\n",
        "for x in range (p_trials):\n",
        "  run(p_seed + x, p_epoch, p_kernel_size, p_logdir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCeY_fku922x",
        "outputId": "302f6740-6427-4b70-8b59-ece7fae00f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeds: 0\n",
            "Epoch: 2\n",
            "Trials: 10\n",
            "Kernel size: 5\n",
            "GPU: 0\n",
            "Logdir: modelM5\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:992: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.835055\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.672545\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.446485\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.381814\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.333888\n",
            "Best accuracy! correct images:  9892\n",
            "\n",
            "Test set: Average loss: 0.1459, Accuracy: 9892/10000 (98.92%) (best: 98.92%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.322609\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.246928\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.257343\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.147037\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.212519\n",
            "\n",
            "Test set: Average loss: 0.1495, Accuracy: 9817/10000 (98.17%) (best: 98.92%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.773786\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.613684\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.504440\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.368925\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.293218\n",
            "Best accuracy! correct images:  9885\n",
            "\n",
            "Test set: Average loss: 0.1281, Accuracy: 9885/10000 (98.85%) (best: 98.85%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.225022\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.228377\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.178184\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.223749\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.160537\n",
            "Best accuracy! correct images:  9900\n",
            "\n",
            "Test set: Average loss: 0.1076, Accuracy: 9900/10000 (99.00%) (best: 99.00%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.534251\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.655485\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.418252\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.396349\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.302562\n",
            "Best accuracy! correct images:  9896\n",
            "\n",
            "Test set: Average loss: 0.1358, Accuracy: 9896/10000 (98.96%) (best: 98.96%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.275565\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.157069\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.266565\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.225049\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.127945\n",
            "Best accuracy! correct images:  9924\n",
            "\n",
            "Test set: Average loss: 0.0775, Accuracy: 9924/10000 (99.24%) (best: 99.24%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.715487\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.598849\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.385839\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.393501\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.222687\n",
            "Best accuracy! correct images:  9877\n",
            "\n",
            "Test set: Average loss: 0.1197, Accuracy: 9877/10000 (98.77%) (best: 98.77%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.250755\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.177847\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.159880\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.119191\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.167821\n",
            "Best accuracy! correct images:  9912\n",
            "\n",
            "Test set: Average loss: 0.0726, Accuracy: 9912/10000 (99.12%) (best: 99.12%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.723286\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.652956\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.526345\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.312364\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.320387\n",
            "Best accuracy! correct images:  9888\n",
            "\n",
            "Test set: Average loss: 0.1417, Accuracy: 9888/10000 (98.88%) (best: 98.88%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.232118\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.219850\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.220962\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.205403\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.205781\n",
            "Best accuracy! correct images:  9894\n",
            "\n",
            "Test set: Average loss: 0.0872, Accuracy: 9894/10000 (98.94%) (best: 98.94%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.751879\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.702585\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.476892\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.338829\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.273951\n",
            "Best accuracy! correct images:  9879\n",
            "\n",
            "Test set: Average loss: 0.1521, Accuracy: 9879/10000 (98.79%) (best: 98.79%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.276195\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.288302\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.257404\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.163721\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.157312\n",
            "Best accuracy! correct images:  9927\n",
            "\n",
            "Test set: Average loss: 0.0722, Accuracy: 9927/10000 (99.27%) (best: 99.27%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.838977\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.657065\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.418213\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.426445\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.310780\n",
            "Best accuracy! correct images:  9887\n",
            "\n",
            "Test set: Average loss: 0.1390, Accuracy: 9887/10000 (98.87%) (best: 98.87%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.292385\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.275872\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.239459\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.183652\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.188473\n",
            "Best accuracy! correct images:  9901\n",
            "\n",
            "Test set: Average loss: 0.0873, Accuracy: 9901/10000 (99.01%) (best: 99.01%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.775707\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.630850\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.442278\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.318756\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.291722\n",
            "Best accuracy! correct images:  9881\n",
            "\n",
            "Test set: Average loss: 0.1375, Accuracy: 9881/10000 (98.81%) (best: 98.81%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.285301\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.206047\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.195721\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.233926\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.167903\n",
            "Best accuracy! correct images:  9898\n",
            "\n",
            "Test set: Average loss: 0.1079, Accuracy: 9898/10000 (98.98%) (best: 98.98%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.617493\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.657929\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.403715\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.383419\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.309708\n",
            "Best accuracy! correct images:  9864\n",
            "\n",
            "Test set: Average loss: 0.1369, Accuracy: 9864/10000 (98.64%) (best: 98.64%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.260839\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.275594\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.176144\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.182208\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.176965\n",
            "Best accuracy! correct images:  9917\n",
            "\n",
            "Test set: Average loss: 0.0769, Accuracy: 9917/10000 (99.17%) (best: 99.17%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.667550\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.564979\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.479860\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.354094\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.328977\n",
            "Best accuracy! correct images:  9896\n",
            "\n",
            "Test set: Average loss: 0.1449, Accuracy: 9896/10000 (98.96%) (best: 98.96%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.271972\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.253895\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.174983\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.168545\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.140008\n",
            "\n",
            "Test set: Average loss: 0.1295, Accuracy: 9793/10000 (97.93%) (best: 98.96%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "CQsoA9BL-ucR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import module\n",
        "import sys\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "\n",
        "def run(p_seed=0, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "\n",
        "    # enable GPU usage ------------------------------------------------------------#\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # memuat data yang telah di train sebelumnya\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # pemilihan model yang akan digunakan\n",
        "    if(p_kernel_size == 3):\n",
        "        model1 = ModelM3().to(device)\n",
        "    elif(p_kernel_size == 5):\n",
        "        model1 = ModelM5().to(device)\n",
        "    elif(p_kernel_size == 7):\n",
        "        model1 = ModelM7().to(device)\n",
        "\n",
        "    model1.load_state_dict(torch.load(\"MnistSimpleCNN/logs/%s/model%03d.pth\"%(p_logdir,p_seed)))\n",
        "\n",
        "    model1.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    wrong_images = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model1(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            wrong_images.extend(np.nonzero(~pred.eq(target.view_as(pred)).cpu().numpy())[0]+(100*batch_idx))\n",
        "\n",
        "    np.savetxt(\"MnistSimpleCNN/logs/%s/wrong%03d.txt\"%(p_logdir,p_seed), wrong_images, fmt=\"%d\")\n",
        "    print(len(wrong_images), wrong_images)\n",
        "\n",
        "p_seed = int(input (\"Seeds: \")) # input seeds value\n",
        "p_trials = int(input (\"Trials: \")) #input trial value\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #input size kernel\n",
        "p_logdir = input (\"Logdir: \") #input model\n",
        "\n",
        "for x in range (p_trials):\n",
        "  run(p_seed + x, p_kernel_size, p_logdir)"
      ],
      "metadata": {
        "id": "1wF9IjL_924p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23197ca-09cd-4014-b342-fd97929bf13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeds: 0\n",
            "Trials: 10\n",
            "Kernel size: 5\n",
            "Logdir: modelM5\n",
            "108 [193, 359, 445, 449, 582, 625, 646, 659, 674, 716, 938, 947, 956, 965, 1014, 1156, 1226, 1232, 1290, 1299, 1328, 1527, 1621, 1681, 1709, 1790, 1868, 1901, 2035, 2040, 2098, 2118, 2135, 2182, 2189, 2224, 2266, 2293, 2308, 2358, 2462, 2488, 2582, 2597, 2823, 2927, 2939, 3005, 3073, 3132, 3225, 3384, 3422, 3475, 3534, 3558, 3762, 3767, 3808, 3821, 3846, 3853, 3869, 3906, 3985, 4065, 4176, 4201, 4248, 4284, 4369, 4443, 4497, 4547, 4551, 4571, 4740, 4759, 4761, 4823, 4874, 4990, 5165, 5457, 5888, 5955, 6065, 6505, 6558, 6576, 7233, 8020, 8094, 8279, 8408, 8504, 8527, 9009, 9015, 9530, 9627, 9664, 9679, 9693, 9729, 9749, 9754, 9904]\n",
            "100 [8, 193, 358, 445, 449, 571, 716, 720, 726, 740, 938, 1039, 1112, 1156, 1226, 1232, 1242, 1299, 1328, 1393, 1403, 1522, 1721, 1737, 1754, 1847, 1868, 1901, 1911, 2024, 2035, 2040, 2098, 2118, 2130, 2148, 2182, 2224, 2293, 2433, 2447, 2462, 2488, 2597, 2823, 3073, 3132, 3225, 3384, 3422, 3534, 3558, 3726, 3756, 3762, 3767, 3846, 3906, 4007, 4053, 4199, 4201, 4547, 4551, 4740, 4761, 4783, 4860, 5159, 5165, 5457, 5654, 5888, 5955, 5997, 6042, 6576, 6625, 6783, 6883, 7856, 7902, 7915, 7928, 8061, 8094, 8275, 8316, 8387, 8391, 8408, 8527, 9009, 9015, 9024, 9729, 9749, 9754, 9792, 9922]\n",
            "76 [445, 449, 582, 625, 659, 674, 740, 938, 1014, 1226, 1232, 1260, 1299, 1364, 1393, 1459, 1551, 1621, 1737, 1901, 2035, 2040, 2118, 2130, 2135, 2148, 2182, 2293, 2338, 2447, 2462, 2582, 2597, 2654, 3062, 3073, 3132, 3422, 3520, 3534, 3558, 3726, 3846, 3906, 4065, 4092, 4163, 4201, 4207, 4224, 4497, 4547, 4740, 4860, 5937, 6554, 6558, 6559, 6571, 6576, 6578, 6597, 6625, 7216, 8095, 8279, 8316, 8408, 8527, 9009, 9642, 9664, 9669, 9679, 9692, 9729]\n",
            "88 [193, 247, 412, 447, 582, 619, 674, 716, 740, 956, 1112, 1156, 1226, 1232, 1299, 1393, 1403, 1527, 1621, 1737, 1754, 1773, 1790, 1901, 1911, 2018, 2035, 2040, 2130, 2148, 2182, 2266, 2447, 2462, 2488, 2582, 2597, 2705, 2939, 3073, 3132, 3225, 3533, 3534, 3558, 3726, 3762, 3767, 3846, 3906, 4201, 4507, 4740, 4761, 4783, 4860, 5159, 5457, 5888, 5937, 5955, 5972, 6576, 6625, 6651, 6783, 6883, 7812, 8275, 8279, 8316, 8325, 8387, 8408, 8527, 9009, 9015, 9019, 9024, 9071, 9505, 9540, 9679, 9729, 9749, 9754, 9792, 9922]\n",
            "106 [259, 321, 445, 582, 583, 613, 625, 646, 659, 674, 716, 947, 965, 1014, 1226, 1232, 1299, 1364, 1393, 1459, 1527, 1681, 1709, 1737, 1790, 1901, 1965, 2035, 2118, 2130, 2135, 2148, 2182, 2266, 2433, 2447, 2454, 2462, 2488, 2532, 2597, 2654, 2959, 3030, 3073, 3225, 3365, 3384, 3422, 3475, 3534, 3558, 3726, 3762, 3846, 3853, 3906, 4065, 4163, 4176, 4201, 4271, 4360, 4497, 4505, 4507, 4547, 4571, 4620, 4699, 4723, 4814, 4860, 5407, 5449, 5937, 5972, 5981, 5997, 6042, 6425, 6532, 6538, 6554, 6555, 6558, 6571, 6574, 6576, 6597, 6625, 6755, 7472, 8094, 8279, 8320, 8408, 8527, 9642, 9664, 9679, 9693, 9698, 9729, 9839, 9888]\n",
            "73 [447, 449, 582, 646, 674, 740, 938, 947, 1039, 1226, 1232, 1260, 1299, 1364, 1393, 1425, 1621, 1681, 1716, 1737, 1878, 1901, 1911, 2035, 2040, 2090, 2130, 2135, 2148, 2182, 2293, 2318, 2447, 2462, 2534, 2597, 2654, 3060, 3073, 3225, 3288, 3534, 3558, 3726, 3906, 3976, 4018, 4065, 4207, 4382, 4384, 4443, 4740, 4823, 4860, 5887, 5936, 5937, 6558, 6576, 6597, 6625, 6651, 8095, 8279, 8316, 8387, 8408, 8527, 9009, 9664, 9729, 9792]\n",
            "99 [8, 193, 359, 445, 582, 625, 646, 674, 726, 882, 938, 1039, 1226, 1232, 1260, 1299, 1364, 1393, 1508, 1594, 1621, 1737, 1754, 1878, 1901, 1911, 2035, 2040, 2049, 2118, 2182, 2237, 2293, 2358, 2387, 2406, 2414, 2462, 2488, 2523, 2597, 2760, 2823, 2939, 2979, 3005, 3073, 3132, 3225, 3534, 3558, 3626, 3821, 3846, 3850, 3869, 3906, 3985, 4163, 4207, 4224, 4369, 4497, 4500, 4551, 4585, 4740, 4761, 4814, 4823, 5457, 5678, 5887, 5937, 5955, 5972, 6505, 6571, 6576, 6592, 6625, 6783, 6883, 7216, 8020, 8275, 8279, 8316, 8408, 9009, 9015, 9024, 9530, 9642, 9664, 9700, 9729, 9749, 9754]\n",
            "102 [43, 321, 359, 449, 464, 490, 625, 646, 659, 883, 938, 947, 1232, 1290, 1299, 1378, 1611, 1621, 1681, 1716, 1737, 1901, 1911, 2040, 2098, 2293, 2308, 2462, 2488, 2597, 2823, 2927, 2945, 3005, 3060, 3073, 3225, 3250, 3384, 3448, 3475, 3534, 3558, 3762, 3821, 3869, 3906, 3946, 3985, 4018, 4176, 4201, 4248, 4306, 4369, 4384, 4443, 4497, 4504, 4551, 4615, 4668, 4740, 4761, 4823, 4990, 5086, 5165, 5457, 5955, 5997, 6065, 6554, 6555, 6569, 6576, 6625, 6783, 6883, 7212, 7216, 7441, 8165, 8275, 8277, 8279, 8408, 8607, 9009, 9595, 9664, 9700, 9729, 9749, 9754, 9762, 9770, 9811, 9828, 9850, 9904, 9905]\n",
            "83 [104, 259, 447, 449, 582, 625, 659, 674, 716, 938, 965, 1050, 1226, 1232, 1299, 1364, 1681, 1709, 1737, 1878, 1901, 1911, 2018, 2035, 2040, 2098, 2118, 2130, 2135, 2148, 2182, 2293, 2447, 2454, 2462, 2582, 2597, 2654, 2939, 3073, 3422, 3475, 3534, 3558, 3749, 3762, 3846, 3906, 4163, 4201, 4284, 4497, 4507, 4547, 4699, 4740, 4783, 4814, 4860, 5888, 5955, 6161, 6172, 6173, 6559, 6571, 6576, 6625, 8095, 8275, 8279, 8408, 8527, 9009, 9015, 9540, 9642, 9664, 9669, 9679, 9729, 9749, 9754]\n",
            "104 [184, 247, 435, 447, 449, 582, 646, 659, 674, 740, 938, 947, 1014, 1039, 1050, 1226, 1232, 1299, 1364, 1393, 1527, 1621, 1681, 1709, 1737, 1754, 1782, 1790, 1878, 1901, 2035, 2040, 2118, 2130, 2135, 2148, 2182, 2266, 2293, 2447, 2462, 2488, 2582, 2597, 2654, 2927, 2939, 3073, 3132, 3225, 3288, 3422, 3475, 3534, 3558, 3726, 3762, 3767, 3821, 3846, 3906, 4007, 4065, 4163, 4176, 4201, 4207, 4224, 4497, 4513, 4699, 4731, 4740, 4761, 4783, 4823, 4860, 4879, 5937, 5972, 6554, 6555, 6558, 6559, 6571, 6576, 6578, 6597, 6625, 8095, 8279, 8316, 8408, 8527, 9009, 9015, 9019, 9642, 9664, 9679, 9698, 9729, 9749, 9792]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## homo ensembel"
      ],
      "metadata": {
        "id": "YJ5Dk2hl-2k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "cnt = 1\n",
        "best = 10000\n",
        "curr = 10000\n",
        "\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #input size kernel\n",
        "KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(i+1,10):\n",
        "        for k in range(j+1,10):\n",
        "            w1 = np.loadtxt(\"MnistSimpleCNN/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, i)).astype(np.int)\n",
        "            w2 = np.loadtxt(\"MnistSimpleCNN/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, j)).astype(np.int)\n",
        "            w3 = np.loadtxt(\"MnistSimpleCNN/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, k)).astype(np.int)\n",
        "\n",
        "            board = np.zeros((10000))\n",
        "            board[w1] += 1\n",
        "            board[w2] += 1\n",
        "            board[w3] += 1\n",
        "            board = board // 2\n",
        "            curr = np.sum(board)\n",
        "            if curr < best:\n",
        "                best = curr\n",
        "            print(\"%4d %4d %4d %4d %4d %4d\"%(cnt, len(w1), len(w2), len(w3), curr, best))\n",
        "            cnt += 1"
      ],
      "metadata": {
        "id": "furS4Ew3-5bT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d2c88bd-df81-43c1-ad05-d6b4330068b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel size: 5\n",
            "   1  108  100   76   76   76\n",
            "   2  108  100   88   86   76\n",
            "   3  108  100  106   88   76\n",
            "   4  108  100   73   79   76\n",
            "   5  108  100   99   85   76\n",
            "   6  108  100  102   85   76\n",
            "   7  108  100   83   77   76\n",
            "   8  108  100  104   93   76\n",
            "   9  108   76   88   73   73\n",
            "  10  108   76  106   79   73\n",
            "  11  108   76   73   66   66\n",
            "  12  108   76   99   80   66\n",
            "  13  108   76  102   80   66\n",
            "  14  108   76   83   71   66\n",
            "  15  108   76  104   86   66\n",
            "  16  108   88  106   82   66\n",
            "  17  108   88   73   75   66\n",
            "  18  108   88   99   80   66\n",
            "  19  108   88  102   85   66\n",
            "  20  108   88   83   77   66\n",
            "  21  108   88  104   86   66\n",
            "  22  108  106   73   74   66\n",
            "  23  108  106   99   91   66\n",
            "  24  108  106  102   90   66\n",
            "  25  108  106   83   84   66\n",
            "  26  108  106  104   90   66\n",
            "  27  108   73   99   75   66\n",
            "  28  108   73  102   74   66\n",
            "  29  108   73   83   71   66\n",
            "  30  108   73  104   82   66\n",
            "  31  108   99  102   82   66\n",
            "  32  108   99   83   83   66\n",
            "  33  108   99  104   92   66\n",
            "  34  108  102   83   82   66\n",
            "  35  108  102  104   85   66\n",
            "  36  108   83  104   87   66\n",
            "  37  100   76   88   73   66\n",
            "  38  100   76  106   69   66\n",
            "  39  100   76   73   59   59\n",
            "  40  100   76   99   75   59\n",
            "  41  100   76  102   65   59\n",
            "  42  100   76   83   68   59\n",
            "  43  100   76  104   77   59\n",
            "  44  100   88  106   78   59\n",
            "  45  100   88   73   70   59\n",
            "  46  100   88   99   75   59\n",
            "  47  100   88  102   70   59\n",
            "  48  100   88   83   76   59\n",
            "  49  100   88  104   81   59\n",
            "  50  100  106   73   65   59\n",
            "  51  100  106   99   78   59\n",
            "  52  100  106  102   71   59\n",
            "  53  100  106   83   77   59\n",
            "  54  100  106  104   89   59\n",
            "  55  100   73   99   71   59\n",
            "  56  100   73  102   66   59\n",
            "  57  100   73   83   63   59\n",
            "  58  100   73  104   72   59\n",
            "  59  100   99  102   70   59\n",
            "  60  100   99   83   75   59\n",
            "  61  100   99  104   82   59\n",
            "  62  100  102   83   62   59\n",
            "  63  100  102  104   77   59\n",
            "  64  100   83  104   81   59\n",
            "  65   76   88  106   68   59\n",
            "  66   76   88   73   58   58\n",
            "  67   76   88   99   71   58\n",
            "  68   76   88  102   60   58\n",
            "  69   76   88   83   73   58\n",
            "  70   76   88  104   81   58\n",
            "  71   76  106   73   67   58\n",
            "  72   76  106   99   68   58\n",
            "  73   76  106  102   71   58\n",
            "  74   76  106   83   72   58\n",
            "  75   76  106  104   83   58\n",
            "  76   76   73   99   65   58\n",
            "  77   76   73  102   64   58\n",
            "  78   76   73   83   66   58\n",
            "  79   76   73  104   74   58\n",
            "  80   76   99  102   70   58\n",
            "  81   76   99   83   70   58\n",
            "  82   76   99  104   80   58\n",
            "  83   76  102   83   63   58\n",
            "  84   76  102  104   79   58\n",
            "  85   76   83  104   78   58\n",
            "  86   88  106   73   61   58\n",
            "  87   88  106   99   71   58\n",
            "  88   88  106  102   67   58\n",
            "  89   88  106   83   77   58\n",
            "  90   88  106  104   84   58\n",
            "  91   88   73   99   68   58\n",
            "  92   88   73  102   64   58\n",
            "  93   88   73   83   67   58\n",
            "  94   88   73  104   79   58\n",
            "  95   88   99  102   65   58\n",
            "  96   88   99   83   74   58\n",
            "  97   88   99  104   82   58\n",
            "  98   88  102   83   64   58\n",
            "  99   88  102  104   80   58\n",
            " 100   88   83  104   88   58\n",
            " 101  106   73   99   64   58\n",
            " 102  106   73  102   66   58\n",
            " 103  106   73   83   71   58\n",
            " 104  106   73  104   80   58\n",
            " 105  106   99  102   75   58\n",
            " 106  106   99   83   72   58\n",
            " 107  106   99  104   85   58\n",
            " 108  106  102   83   74   58\n",
            " 109  106  102  104   79   58\n",
            " 110  106   83  104   87   58\n",
            " 111   73   99  102   69   58\n",
            " 112   73   99   83   65   58\n",
            " 113   73   99  104   75   58\n",
            " 114   73  102   83   61   58\n",
            " 115   73  102  104   75   58\n",
            " 116   73   83  104   78   58\n",
            " 117   99  102   83   69   58\n",
            " 118   99  102  104   81   58\n",
            " 119   99   83  104   82   58\n",
            " 120  102   83  104   78   58\n"
          ]
        }
      ]
    }
  ]
}