{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week9_3.3.ConciseImplementationofLinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4bnpL4nd0V6"
      },
      "outputs": [],
      "source": [
        "!pip install d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import module"
      ],
      "metadata": {
        "id": "R8zU2nfceOiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l"
      ],
      "metadata": {
        "id": "Hx3tbp0reUSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generate datasets"
      ],
      "metadata": {
        "id": "LMwBcQL7eVFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_w = tf.constant([2, -3.4])\n",
        "true_b = 4.2\n",
        "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
      ],
      "metadata": {
        "id": "P2nf07tYeXo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reading datasets"
      ],
      "metadata": {
        "id": "nwDMytvpecFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True):  #@save\"\"\"Construct a TensorFlow data iterator.\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data_arrays)\n",
        "    if is_train:\n",
        "        dataset = dataset.shuffle(buffer_size=1000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "batch_size = 10\n",
        "data_iter = load_array((features, labels), batch_size)"
      ],
      "metadata": {
        "id": "Oga-amp-efdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use iter to construct a Python iterator and use next to obtain the first item from the iterator."
      ],
      "metadata": {
        "id": "ce99puE9eqLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(data_iter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZkjIiIwerZh",
        "outputId": "de0a49ad-bce5-4deb-81b1-d5fac8cde9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
              " array([[-0.7855348 ,  0.9105857 ],\n",
              "        [-0.79782057,  0.6912928 ],\n",
              "        [ 0.37471572, -2.0143378 ],\n",
              "        [-0.15483612, -0.19595227],\n",
              "        [-0.21722475,  0.8540268 ],\n",
              "        [ 1.7054065 ,  0.5598915 ],\n",
              "        [-0.7505607 , -0.02211357],\n",
              "        [ 0.7265861 , -1.1477206 ],\n",
              "        [-0.583126  , -0.6871914 ],\n",
              "        [ 0.9766279 , -1.2944337 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              " array([[-0.45619205],\n",
              "        [ 0.2706712 ],\n",
              "        [11.798034  ],\n",
              "        [ 4.5473676 ],\n",
              "        [ 0.85687184],\n",
              "        [ 5.706851  ],\n",
              "        [ 2.7971098 ],\n",
              "        [ 9.576376  ],\n",
              "        [ 5.3657393 ],\n",
              "        [10.568655  ]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## defining the model"
      ],
      "metadata": {
        "id": "ULmrPHHreuMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# `keras` is the high-level API for TensorFlow\n",
        "net = tf.keras.Sequential()\n",
        "net.add(tf.keras.layers.Dense(1))"
      ],
      "metadata": {
        "id": "87Smm4Nje0d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## initializing model parameters"
      ],
      "metadata": {
        "id": "Kh8-kHXDe8Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initializer = tf.initializers.RandomNormal(stddev=0.01)\n",
        "net = tf.keras.Sequential()\n",
        "net.add(tf.keras.layers.Dense(1, kernel_initializer=initializer))"
      ],
      "metadata": {
        "id": "1ddLmHstfDRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## defining the loss funtion"
      ],
      "metadata": {
        "id": "EoyLdsLKfPMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.MeanSquaredError()"
      ],
      "metadata": {
        "id": "5H-v6V8EfTU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## defining the optimization algorithim"
      ],
      "metadata": {
        "id": "uKiC7n26fV2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = tf.keras.optimizers.SGD(learning_rate=0.03)"
      ],
      "metadata": {
        "id": "d3tToJf3fkwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training"
      ],
      "metadata": {
        "id": "9G8ZC9B0fmt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    for X, y in data_iter:\n",
        "        with tf.GradientTape() as tape:\n",
        "            l = loss(net(X, training=True), y)\n",
        "        grads = tape.gradient(l, net.trainable_variables)\n",
        "        trainer.apply_gradients(zip(grads, net.trainable_variables))\n",
        "    l = loss(net(features), labels)\n",
        "    print(f'epoch {epoch + 1}, loss {l:f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr8tEZwmfozT",
        "outputId": "b5d74f0a-49dd-41dd-a6ea-89c9d10027a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.000385\n",
            "epoch 2, loss 0.000098\n",
            "epoch 3, loss 0.000098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we compare the model parameters learned by training on finite data and the actual parameters that generated our dataset. To access parameters, we first access the layer that we need from net and then access that layerâ€™s weights and bias. As in our from-scratch implementation, note that our estimated parameters are close to their ground-truth counterparts."
      ],
      "metadata": {
        "id": "HOgOLaogfxUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = net.get_weights()[0]\n",
        "print('error in estimating w', true_w - tf.reshape(w, true_w.shape))\n",
        "b = net.get_weights()[1]\n",
        "print('error in estimating b', true_b - b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_jNBBkdfx8w",
        "outputId": "e0935b11-e4c3-48ee-e7cf-137e5212d804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error in estimating w tf.Tensor([-0.00012422 -0.00023961], shape=(2,), dtype=float32)\n",
            "error in estimating b [-0.00034237]\n"
          ]
        }
      ]
    }
  ]
}